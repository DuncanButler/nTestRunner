// ------------------------------------------------------------------------------
//  <auto-generated>
//      This code was generated by SpecFlow (http://www.specflow.org/).
//      SpecFlow Version:1.5.0.0
//      Runtime Version:4.0.30319.225
// 
//      Changes to this file may cause incorrect behavior and will be lost if
//      the code is regenerated.
//  </auto-generated>
// ------------------------------------------------------------------------------
#region Designer generated code
namespace nTestRunner.features.Features
{
    using TechTalk.SpecFlow;
    
    
    [System.CodeDom.Compiler.GeneratedCodeAttribute("TechTalk.SpecFlow", "1.5.0.0")]
    [System.Runtime.CompilerServices.CompilerGeneratedAttribute()]
    [NUnit.Framework.TestFixtureAttribute()]
    [NUnit.Framework.DescriptionAttribute("nTestRunner solution change")]
    public partial class NTestRunnerSolutionChangeFeature
    {
        
        private static TechTalk.SpecFlow.ITestRunner testRunner;
        
#line 1 "nTestRunnerRunning.feature"
#line hidden
        
        [NUnit.Framework.TestFixtureSetUpAttribute()]
        public virtual void FeatureSetup()
        {
            testRunner = TechTalk.SpecFlow.TestRunnerManager.GetTestRunner();
            TechTalk.SpecFlow.FeatureInfo featureInfo = new TechTalk.SpecFlow.FeatureInfo(new System.Globalization.CultureInfo("en-US"), "nTestRunner solution change", @"As a developer
In order to get rapid feedback
When I save a file, the program should be compiled and all tests run and the results
stored in a file in the same format as nunit, so I can use beacons to view the results of the
test.

The file watcher watches the solution file, and the immediate project directories, when a change in these watched areas is detected
then the watcher is stopped, the build and test cycle started, and the results written to the xml results file in nunit format, if the
runner display is set then it is activated with the results from the build test cycle.", GenerationTargetLanguage.CSharp, ((string[])(null)));
            testRunner.OnFeatureStart(featureInfo);
        }
        
        [NUnit.Framework.TestFixtureTearDownAttribute()]
        public virtual void FeatureTearDown()
        {
            testRunner.OnFeatureEnd();
            testRunner = null;
        }
        
        public virtual void ScenarioSetup(TechTalk.SpecFlow.ScenarioInfo scenarioInfo)
        {
            testRunner.OnScenarioStart(scenarioInfo);
        }
        
        [NUnit.Framework.TearDownAttribute()]
        public virtual void ScenarioTearDown()
        {
            testRunner.OnScenarioEnd();
        }
        
        [NUnit.Framework.TestAttribute()]
        [NUnit.Framework.DescriptionAttribute("with default configuration")]
        public virtual void WithDefaultConfiguration()
        {
            TechTalk.SpecFlow.ScenarioInfo scenarioInfo = new TechTalk.SpecFlow.ScenarioInfo("with default configuration", ((string[])(null)));
#line 12
this.ScenarioSetup(scenarioInfo);
#line 13
 testRunner.Given("I am a developer");
#line 14
 testRunner.When("I attempt to run the test runner: with arguments \' \'");
#line 15
 testRunner.And("I attempt to change a file: source file");
#line 16
 testRunner.Then("I see text containing display text \'Running build using MSBuild4\'");
#line 17
 testRunner.And("I see text containing display text \'Running tests using MSpec, MSTest, NUnit\'");
#line 18
 testRunner.And("I see text containing display text \'Waiting\'");
#line hidden
            testRunner.CollectScenarioErrors();
        }
    }
}
#endregion
